{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readtags(doc):\n",
    "    tree = ET.parse(doc)\n",
    "    root = tree.getroot()\n",
    "    name = doc.replace('.xml','')\n",
    "    name = []\n",
    "    for description in root.iter('seg'):\n",
    "        p = description.text\n",
    "        p=p.replace('\\t','')\n",
    "        p=p.replace('\\n','')\n",
    "        p = [p]\n",
    "        name.append(p)\n",
    "    return name\n",
    "\n",
    "def readother(doc):\n",
    "    tree = ET.parse(doc)\n",
    "    root = tree.getroot()\n",
    "    name = doc.replace('.xml','')\n",
    "    name = []\n",
    "    for description in root.iter('seg'):\n",
    "        p = [description.text]\n",
    "        name.append(p)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese = readtags('Chinese.xml')\n",
    "english = readtags('English.xml')\n",
    "arabic = readtags('Arabic.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(english)):\n",
    "    english[i] = [word.lower() for word in english[i] if re.match('^[a-zA-Z]+', word)]\n",
    "    english[i] = (' ').join(english[i])\n",
    "    english[i] = [(re.sub(r'[^\\w\\s]','',english[i]))]\n",
    "    english[i] = (' ').join(english[i])\n",
    "df = pd.DataFrame()\n",
    "lan = [\"English\"] * len(english)\n",
    "data_1 = pd.DataFrame({\"Text\": english,\"Language\": lan})\n",
    "df.append(data_1)\n",
    "data_1.head(1)\n",
    "for i in range(len(arabic)):\n",
    "    arabic[i] = (' ').join(arabic[i]).replace('.','')\n",
    "df = pd.DataFrame()\n",
    "lan = [\"Arabic\"] * len(arabic)\n",
    "data_2 = pd.DataFrame({\"Text\": arabic,\"Language\": lan})\n",
    "df.append(data_2)\n",
    "data_2.head(1)\n",
    "for i in range(len(chinese)):\n",
    "    chinese[i] = ('').join(chinese[i])\n",
    "    chinese[i] = (re.sub(r'[^\\w\\s]','',chinese[i]))\n",
    "df = pd.DataFrame()\n",
    "lan = [\"Chinese\"] * len(chinese)\n",
    "data_5 = pd.DataFrame({\"Text\": chinese,\"Language\": lan})\n",
    "df.append(data_5)\n",
    "data_5.head(1)\n",
    "data = pd.concat([data_1, data_2,data_5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25748</th>\n",
       "      <td>English</td>\n",
       "      <td>and he said unto him well thou good servant be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28455</th>\n",
       "      <td>English</td>\n",
       "      <td>it is reported commonly that there is fornicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63061</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>拉 班對 他 說  我 若 在 你 眼前 蒙恩  請 你 仍與 我 同住  因為 我 已 算...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42033</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>وكانت ايضا حرب مع الفلسطينيين فقتل الحانان بن ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>وان اضطجع معها رجل فكان طمثها عليه يكون نجسا س...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Language                                               Text\n",
       "25748  English  and he said unto him well thou good servant be...\n",
       "28455  English  it is reported commonly that there is fornicat...\n",
       "63061  Chinese  拉 班對 他 說  我 若 在 你 眼前 蒙恩  請 你 仍與 我 同住  因為 我 已 算...\n",
       "42033   Arabic  وكانت ايضا حرب مع الفلسطينيين فقتل الحانان بن ...\n",
       "34294   Arabic  وان اضطجع معها رجل فكان طمثها عليه يكون نجسا س..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words based Probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 28450)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "train = data['Text'][:9000]\n",
    "test =  data['Text'][3305:]\n",
    "X_train_counts = count_vect.fit_transform(train)\n",
    "test = count_vect.transform(test)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, data['Language'][:9000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9980666666666667"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(test)\n",
    "np.mean(predicted == data['Language'][3305:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = count_vect.transform([\"god is\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability that the text is ARABIC, CHINESE, ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.68671446e-06, 1.32082217e-05, 9.99979105e-01]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If i use a combination of both English and Arabic we can see that the probability of the text being arabic increases whereas the probability if ut being english decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = count_vect.transform([\"god is الله\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- English = 99 %\n",
    "- Arabic = 0.002 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.36333889e-03, 2.50012128e-05, 9.97611660e-01]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that I use all the three languages the same number of times, the probabilites are comparable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = count_vect.transform([\"god 神 الله\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- English = 44 %\n",
    "- Arabic = 55 %\n",
    "- Chinese = 0.0005 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50724477, 0.00411136, 0.48864387]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chinese predictions are weak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23112025, 0.6085612 , 0.16031855]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = count_vect.transform([\"拉 班對\"])\n",
    "clf.predict_proba(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF based Probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sangarshanan Veera\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9000, 28450)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, data['Language'][:9000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = count_vect.transform([\"god is\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.12596145e-04, 2.39232286e-04, 9.99548172e-01]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- English = 99.99 %\n",
    "- Arabic = 0.0008 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.04955296e-04, 3.17871283e-06, 9.99191866e-01]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = count_vect.transform([\"god is الله\"])\n",
    "clf.predict_proba(s)c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- English = 60.302607 %\n",
    "- Arabic = 39.556258 %\n",
    "- Chinese = 0.141135 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39556258, 0.00141135, 0.60302607]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = count_vect.transform([\"god 神 الله\"])\n",
    "clf.predict_proba(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333691, 0.33332619, 0.33333691]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = count_vect.transform([\"拉\"])\n",
    "clf.predict_proba(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese Probability is weak in both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
